# 散列与分层时序轮
* https://www.cnblogs.com/frankcui/p/17160317.html
* http://www.cs.columbia.edu/~nahum/w6998/papers/sosp87-timing-wheels.pdf
* https://blog.acolyer.org/2015/11/23/hashed-and-hierarchical-timing-wheels/
* https://www.confluent.io/blog/apache-kafka-purgatory-hierarchical-timing-wheels/
* https://www.youtube.com/watch?v=rvZaS3CXicE
* https://www.lpnote.com/2017/11/15/hashed-and-hierarchical-timing-wheels/

![](./Hashed%20and%20Hierarchical%20Timing%20Wheels.png)  
上面的单个时序槽内的数据以链表展示，实际上可以采用哈希集，从而可以进一步优化检索、去重的性能。  
```java
import java.util.*;

public class HierarchicalTimeWheel {
    private static final int MONTHS_PER_YEAR = 12;
    private static final int DAYS_PER_MONTH = 31;
    private static final int HOURS_PER_DAY = 24;
    private static final int MINUTES_PER_HOUR = 60;
    private static final int SECONDS_PER_MINUTE = 60;

    private enum Wheel {
        YEAR, MONTH, DAY, HOUR, MINUTE;
    }

    private static class Wheel {
        private final int size;
        private final Map<Integer, Set<ScheduledTask>> tasks;

        public Wheel(int size) {
            this.size = size;
            this.tasks = new HashMap<>();
            for (int i = 0; i < size; i++) {
                tasks.put(i, new HashSet<>());
            }
        }

        public int getSize() {
            return size;
        }

        public Set<ScheduledTask> getTasks(int index) {
            return tasks.get(index);
        }
    }

    public static class ScheduledTask {
        private final Runnable task;
        private final long timestamp;

        public ScheduledTask(Runnable task, long timestamp) {
            this.task = task;
            this.timestamp = timestamp;
        }

        public Runnable run() {
            //...
        }
    }

    private final Map<Integer, Wheel> wheels;

    public HierarchicalTimeWheel() {
        this.wheels = new HashMap<>();
        this.wheels.put(Wheel.YEAR, new Wheel(MONTHS_PER_YEAR));
        this.wheels.put(Wheel.MONTH, new Wheel(DAYS_PER_MONTH));
        this.wheels.put(Wheel.DAY, new Wheel(HOURS_PER_DAY));
        this.wheels.put(Wheel.HOUR, new Wheel(MINUTES_PER_HOUR));
        this.wheels.put(Wheel.MINUTE, new Wheel(SECONDS_PER_MINUTE));
    }

    public void insert(ScheduledTask task, long timestamp) {
        long time = timestamp;
        for (Wheel wheel : wheels.values()) {
            int index = (int) (time % wheel.getSize());
            wheel.getTasks(index).add(task);
            time /= wheel.getSize();
        }
    }

    public Set<ScheduledTask> getTasks(long timestamp) {
        long time = timestamp;
        Set<ScheduledTask> tasks = new HashSet<>();
        for (Wheel wheel : wheels.values()) {
            int index = (int) (time % wheel.getSize());
            Set<ScheduledTask> wheelTasks = wheel.getTasks(index);
            if (!wheelTasks.isEmpty()) {
                if (tasks.isEmpty()) tasks.addAll(wheelTasks);
                else tasks.retainAll(wheelTasks);
            }
            time /= wheel.getSize();
        }
        return tasks;
    }
}
```

但是如果数据量非常大，那么每次进行交集操作时间复杂度的性能就会变差（时间复杂度为 O(min(M1, M2))，M 为交集的哈希集的数据量）。  
一个可行的优化方案是按照树结构以及懒更新来进行实现，保证了查询时间复杂度在这种情况下收敛回 O(1)：
* 类似多叉树或者字典树的结构，比如树的根节点为起始，下面有 12 个月的子节点，然后每个月又有大概 30 个日的子节点，如此类推
* 而懒更新在只有需要的时候才创建子节点，如此可以优化无数据的查询以及空间使用率


## 工业实现
[Kafka 分层时序轮的代码实现](https://github.com/apache/kafka/blob/b1796ce6d2c04444a62393fbfd7c61811e001d67/server-common/src/main/java/org/apache/kafka/server/util/timer/TimingWheel.java)  
