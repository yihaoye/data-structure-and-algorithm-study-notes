## 分布式事务
**微服务过多就会引出分布式事务，比如为了某个业务逻辑需要调用多个微服务的 API 但是这多个调用必须保证事务、原子性（要不全部成功或全部失败）**，这个时候不建议去采用下面任何一种方案，而是请把需要事务的微服务聚合成一个单机服务，使用数据库的本地事务。因为不论任何一种方案都会增加系统的复杂度，这样的成本实在是太高了，千万不要因为追求某些设计，而引入不必要的成本和复杂度。  
如果确定需要引入分布式事务可以看看下面几种常见的方案。  

支持分布式事务的数据库：Spanner（Google）  

## [分布式事务最经典的七种解决方案](https://segmentfault.com/a/1190000040321750)

方案 | 特点 | 使用场景 | 缺点
--- | --- | --- | ---
2PC (Two-Phase Commit) | 严格一致性、同步提交 | 银行转账、订单支付（核心交易） | 性能差、阻塞性高，Coordinator 单点问题
TCC (Try-Confirm-Cancel) | 业务自定义的预留+确认/取消 | 金融、电商核心链路（库存扣减、支付锁定） | 开发复杂，需要业务方大量配合
Saga | 异步长事务、补偿型 | 电商下单、物流派送、会员系统等 | 只能保证最终一致性，不保证强一致性
消息最终一致性（基于消息队列） | 轻量，吞吐高 | 电商、营销、积分系统等弱一致场景 | 依赖 MQ，需要处理消息丢失/重复问题

按实际应用比例来说，最多的是：
* 轻量场景（大多数系统） ➔ 基于消息队列的最终一致性（最常见）
* 复杂业务链路（大中型业务） ➔ Saga 模型（补偿事务）
* 极端要求强一致性（银行、金融核心交易） ➔ TCC 或少量 2PC

### Try-Confirm-Cancel
1. 解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。
2. 同步阻塞 - 引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。
3. 数据一致性，有了补偿机制之后，由业务活动管理器控制一致性

对于 TCC 的解释:
* Try 阶段：尝试执行，完成所有业务检查（一致性），预留必须业务资源（准隔离性）
* Confirm 阶段：确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性。要求具备幂等设计，Confirm 失败后需要进行重试。
* Cancel 阶段：取消执行，释放 Try 阶段预留的业务资源，Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。

### 本地消息表
本地消息表这个方案最初是 ebay 提出的 ebay 的完整方案 https://queue.acm.org/detail.cfm?id=1394128 。  
此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。  
![](./%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8.webp)  

### MQ 事务
[如何利用事务消息实现分布式事务](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%AB%98%E6%89%8B%E8%AF%BE/04%20%20%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%EF%BC%9F.md)  
![](./消息队列分布式事务.jpg)  
RocketMQ 和 Kafka 都各自实现了事务功能（实际上其实是对本地消息表的一个封装，将本地消息表移动到了 MQ 内部），但是具体机制有所不同（Kafka 提交失败后只会简单返回报错，RocketMQ 更多保障如下图所示）。  
![](./RocketMQ%20事务.jpg)  

消息队列的事务性保障，仍然只停留在消息被生产者成功发送并持久化到消息队列本身这一步。  
它不直接保证消息被消费者成功拉取、业务逻辑成功执行，以及最终结果的一致性。这些更高层次的保障，需要通过以下机制来协同实现：
* 生产者端：确保消息发送与本地数据库操作的原子性
* 消息队列本身：提供消息的持久化和至少一次投递
* 消费者端：实现幂等性，以应对消息重复投递

### [Saga 事务 / 补偿事务](https://learn.microsoft.com/zh-cn/azure/architecture/reference-architectures/saga/saga)
Saga 核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器 TM 协调（消息队列或编排器），如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。  
Saga 的组成：  
每个 Saga 由一系列 sub-transaction Ti 组成  
每个 Ti 都有对应的补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果，这里的每个 T，都是一个本地事务。  
可以看到，和 TCC 相比，Saga 没有 “预留 try” 动作，它的 Ti 就是直接提交到库。  
Saga 一旦到了 Cancel 阶段，那么 Cancel 在业务逻辑上是不允许失败了。如果因为网络或者其他临时故障，导致没有返回成功，那么 TM 会不断重试，直到 Cancel 返回成功。  

Saga 的执行顺序有两种：  
T1, T2, T3, ..., Tn  
T1, T2, ..., Tj, Cj,..., C2, C1，其中 0 < j < n  

Saga 定义了两种恢复策略：  
向后恢复，即上面提到的第二种执行顺序，其中 j 是发生错误的 sub-transaction，这种做法的效果是撤销掉之前所有成功的 sub-transation，使得整个 Saga 的执行结果撤销。  
向前恢复，适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, ..., Tj (失败), Tj (重试), ..., Tn，其中 j 是发生错误的 sub-transaction。该情况下不需要 Ci。  
这里要注意的是，在 Saga 模式中不能保证隔离性，因为没有锁住资源，其他事务依然可以覆盖或者影响当前事务。  

Saga 事务的特点：  
* 并发度高，不用像 XA 事务那样长期锁定资源
* 需要定义正常操作以及补偿操作，开发量比 XA 大
* 一致性较弱，对于转账，可能发生 A 用户已扣款，最后转账又失败的情况

SAGA 适用的场景较多，长事务适用，对中间结果不敏感的业务场景适用。  
在 Saga 模式中，重试非常重要。如果某个本地事务因为瞬时故障而失败，通常会进行重试，以避免触发补偿流程。重试是达到该本地事务成功的重要手段。但如果重试后仍失败，则会启动补偿流程。  

### 二阶段提交 / Two-phase Commit
说到 2PC 就不得不聊数据库分布式事务中的 XA Transactions。

![](./Two-phase%20Commit.webp)  

在 XA 协议中分为两阶段:  
* 第一阶段：事务管理器要求每个涉及到事务的数据库预提交 (precommit) 此操作，并反映是否可以提交 - 即执行所有事务操作，但不真正提交，而是将结果记录在日志中，并告诉协调者准备好了或无法准备。
* 第二阶段：事务协调器要求每个数据库提交数据，或者回滚数据。

优点：
* 尽量保证了数据的强一致，实现成本较低，在各大主流数据库都有自己实现，对于 MySQL 是从 5.5 开始支持。  

缺点：
* 单点问题：事务管理器在整个流程中扮演的角色很关键，如果其宕机，比如在第一阶段已经完成，在第二阶段正准备提交的时候事务管理器宕机，资源管理器就会一直阻塞，导致数据库无法使用。
* 同步阻塞：在准备就绪之后，资源管理器中的资源一直处于阻塞，直到提交完成，释放资源。
* 数据不一致：两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务 commit 的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了 commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。

总的来说，XA 协议比较简单，成本较低，但是其单点问题，以及不能支持高并发（由于同步阻塞）依然是其最大的弱点。  

### 总结
能不用分布式事务就不用，如果非得使用的话，结合自己的业务分析，看看自己的业务比较适合哪一种，是在乎强一致，还是最终一致即可。上面对解决方案只是一些简单介绍，如果真正的想要落地，其实每种方案需要思考的地方都非常多，复杂度都比较大。  

作者：咖啡拿铁
链接：https://juejin.cn/post/6844903647197806605
