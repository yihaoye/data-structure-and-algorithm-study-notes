# Back Pressure
Backpressure 又称背压、反压，其实是一种现象：在数据流从上游生产者向下游消费者传输的过程中，上游生产速度大于下游消费速度，导致下游的 Buffer 溢出，这种现象就叫做 Backpressure 出现。响应式编程中的背压（Backpressure）概念来源于流体力学的比喻，也和其他工程领域的背压概念相似，比如在管道运输中，气流或液流由于管道突然变细、急弯等原因导致由某处出现了下游向上游的逆向压力，这种情况称为 Backpressure。背压是在软件开发中经常遇到并且有时不得不处理的问题，但这个词以及表达的现象并没有被正确地理解和认识。背压并不是一种机制，也不是一种策略，背压现象中关键是下游的 Buffer 溢出。  


## 背压的例子
### 读写文件
一般写文件比读文件要慢，假设一个磁盘驱动有效的读文件速度是 150MB/s，而写文件速度是 100MB/s，如果要以最快的速度将文件读入内存，同时又以最快的速度将其写回磁盘，则必须每秒缓冲 50MB，这样内存将被不断被堆积，在输入文件被完全读取之前，内存中还有大量的数据没有被写入文件。假设要读入一个 6GB 的文件然后将它写入磁盘，在读完全部文件时，还有 2GB 的内容等待写入。
```
6 GB / 150 MB/s = 40 s
150 MB - 100 MB = 50 MB
50 MB x 40 = 2 GB !!!
```
这将浪费很多的内存，在一些系统上可能超出了可用内存，最终产生 OutOfMemory Exception，这就是由于写文件速度慢于读文件速度产生了背压问题。  

### 服务器通信
另一个关于背压问题的例子是服务器间的通信问题。在普遍采用的微服务架构中，各个服务器的职责一般是独立分散的，当一台服务器向另一台服务器发送请求的速度快于后者处理请求的速度时，通常会出现背压。  
如果服务器 A 向服务器 B 发送 100 个 qps（每秒请求数），但服务器 B 只能处理 75 个 qps，那么对于服务器 B 就有 25 个 qps 的富余。此时服务器 B 可能会落后，因为它需要处理这些请求，或者还需要与下游的其他服务器通信。这是由于服务器处理能力的差异，导致上下游通信的服务器在处理请求时产生了背压问题。  

### 渲染 UI
在渲染 UI 方面也经常发生背压的现象，当程序无法以所需的速度渲染时，就会发生背压，比如 Android App 的卡顿现象是由于应用程序的渲染速度没有达到 60 fps。  


## 如何解决背压
可以看出背压现象在程序开发中普遍存在，而且各个场景下处理背压的思路都差不多。除了扩展可用的计算资源外，如何处理背压问题可以概括为三种可能的选择：
* 控制生产者产生数据的速度以适应消费者的响应速度
* 缓存临时产生的大量数据
* 丢弃上游发出的事件（可能有多种策略）

控制生产者可能是处理背压问题的最优选择，如果这种方案可行的话，它只需要考虑设计好控制机制，而不会有内存和其他资源的开销。在数据消费端不需要额外的内存来缓存数据，也不需要顾虑丢弃数据。不幸的是控制生产者产生数据并不总是可行，比如数据的输入是用户操作，系统本身不能控制程序系统之外的数据生产者。  
缓存是大多数背压问题的解决方式。Backpressure 和 Buffer 是一对相生共存的概念，一方面只有设置了 Buffer，才有 Backpressure 出现；另一方面只要设置了 Buffer，一定存在出现 Backpressure 的风险。使用缓存时要考虑，缓冲区的增长速度有可能在相当长的一段时间内超过它的消耗速度吗？如果缓冲区是无界的，那么缓冲区可能是危险的，这意味着对缓冲区没有大小或时间限制。  
丢弃是最后一种策略，它也经常与缓存相结合。比如基于时间的采样，每秒丢弃 10% 的数据。丢弃的具体策略有多种。  


### 无限缓冲的风险
要小心无限的（unbounded）缓冲（buffer）。一方面如果生产者的速率长期大于消费者的速率，那么多余的流量将无限增加，即使流量可以用某种方式存储，这些流量预期被消费的时间也无限增加，满足不了业务需求。另一方面事实上无法实现真正的无限缓冲，它们最终都将受限于物理资源（内存、硬盘等），资源耗尽时，就不仅仅是流量丢失的问题了。  
如果是有限的缓冲，则当缓冲满了以后，又回到了控制和丢弃策略了。而丢弃可不可行通常得看业务需求，于是早晚又得实现控制策略。  
消息队列（如 Kafka）相当于提供了一个巨大（接近无限）的缓冲，这样它的上下游之间就不需要有压力的传导了，多余的流量全在队列上。  

### 如何实现控制
生产/源头/流量控制分成隐式控制（如 Callstack Blocking）和显式控制（如 Pull 模式）。
* Callstack Blocking 是指阻塞整条调用链，例如提交任务到线程池，拒绝策略是阻塞，则线程池满了以后，整个线程会阻塞在提交的动作上，它隐式地阻塞了同一个线程上游的生产者。如果处理流程不在同一个线程上则难以实现，如任务在多个线程上运行或跨越多个微服务。TCP 是最经典的示例了，协议本身提供流量控制，内核会保存一个有限（bounded）大小的发送缓冲，当缓冲满的时候，会阻塞 send 方法，即 callstack blocking 实现控制，这样接收方的压力就可以传导到发送方的 send 方法了。
* 显式控制是指在业务逻辑中显式地实现生产者和消费者间的沟通达到流量控制的目的（例如 TCP 协议中通过交换当前接收窗口的大小来完成流量控制）。其中拉取（Pull）模式则是比较通用且重要的一种，即任务的趋动是由消费者发起的，而不是生产者。例如 Reactive Stream 里的 API 规定是由订阅者（消费者）调用 request(n) 方法向生产者请求 n 个消息，生产者再调用 onNext() 将 n 个消息提供给消费者。消费者可以按需要获取，生产者也可以按需生产，从而实现生产者控制。

### 丢弃策略
在微服务架构中，通常有一个断路器（Circuit Breaker）的角色，在某个服务压力过大或系统不可用时，不再请求而直接返回默认值，可以认为是一种丢弃策略。  
另外还有一些常见的丢弃策略：
* 丢弃最新的（Drop Latest）：当缓冲区满时，丢弃最新到达的数据，保留已经在缓冲区中的数据。
  * 保留最新的（Keep Latest）：当缓冲区满时，只保留最新的一个而丢弃其余的数据。通常不设大缓冲区，而是将缓冲区大小设为 1，永远只存最后进来的那一个，覆盖掉前一个。
* 丢弃最旧的（Drop Oldest）：当缓冲区满时，丢弃最早到达的数据，为新数据腾出空间。
  * 保留最旧的（Keep Oldest）：当缓冲区满时，只保留最早的一个而丢弃其余的数据。
* 全部丢弃（Drop All）：当缓冲区满时，丢弃所有新到达的数据，保留缓冲区中的数据不变。
* 采样丢弃（Sampling Drop）：按照一定的采样率丢弃数据，例如每隔 n 个数据丢弃一个。
* 限流丢弃（Rate Limiting Drop）：根据预设的速率限制丢弃数据，例如每秒只允许处理 m 个数据，超过的部分丢弃。
* 条件丢弃（Conditional Drop）：根据自定义的条件决定是否丢弃数据，例如根据数据内容或来源。


## 总结
解决背压的策略并不能消除过度生产或者消费不足的问题，它只是把问题转移到一个可以更好处理的操作链上。再次理解背压可以总结为：
1. 永远不要用上游生产速度是否大于下游消费速度来判断某个模块是否需要 Buffer 的支持，因为现实场景是不可预估的，生产速度总是有一定的可能会大于下游消费的速度，所以 Buffer 是永远需要的。只要上游生产速度不会快到让系统崩溃或者应用场景不可接受，那么不用设置 Buffer 上限，从而也就不用考虑 Backpressure 发生。
2. 只有上游生产速度可能会快到让系统崩溃，并且事件是可以丢弃的，才需要设置 Buffer 上限。当 Buffer 有上限的时候，Backpressure 也就有可能出现；一旦 Backpressure 出现，只能选择丢弃，只是具体的丢弃策略可以根据需求而定（全部丢弃、只保留最新的一个而丢弃其余的等等，丢弃根本基本原则）。
3. 如果上游生产速度可能会快到把系统搞崩溃，而事件也不可丢弃，这个时候可能修改程序的设计了：修改代码设计来规避风险，或者修改软件设计、通过让步的方式来从根源上避免问题发生。但这已经不是 Buffer 或者 Backpressure 能解决的问题了。


参考资料：
* [背压 (Back Pressure) 与流量控制](https://lotabout.me/2020/Back-Pressure/)
* [关于背压的理解](https://git4pl.github.io/post/imXjzp6FH/)
* [Backpressure](https://www.cnblogs.com/JaxYoun/p/12401491.html)
